import org.kie.api.runtime._
import org.kie.api.KieServices
import org.kie.api.builder.KieFileSystem
import org.kie.api.io.Resource
import org.kie.api.builder.KieBuilder
import java.util.HashMap

 var kieSession: KieSession = null
 var init: Boolean = false
  
 def initKieSesion(ruleFile: String): Unit = {
    val kieServices: KieServices = KieServices.Factory.get()
    val kFileSystem: KieFileSystem = kieServices.newKieFileSystem();
    val resource: Resource = kieServices.getResources.newFileSystemResource(ruleFile)
    kFileSystem.write("/src/main/resources/rule.drl", ruleFile)
    val builder: KieBuilder = kieServices.newKieBuilder(kFileSystem).buildAll()
    val container: KieContainer = kieServices.newKieContainer(builder.getKieModule.getReleaseId)
    kieSession = container.newKieSession();
    init = true
  }
  
 kieSession.insert(data)
 kieSession.fireAllRules()
 
 
 case class ApplicantForLoan(id: Int, firstName: String, lastName: String, requestAmount: Int, creditScore: Int) extends Serializable {
  private var approved = false
  def getFirstName: String = firstName
  def getLastName: String = lastName
  def getId: Int = id
  def getRequestAmount: Int = requestAmount
  def getCreditScore: Int = creditScore
  def isApproved: Boolean = approved
  def setApproved(_approved: Boolean): Unit = {
    approved = _approved
  }
}

object DroolUtil extends Logging {
  /**
    * loadRules.
    *
    * @return KieBase
    */
  def loadRules: KieBase = {
    val kieServices = KieServices.Factory.get
    val kieContainer = kieServices.getKieClasspathContainer
    kieContainer.getKieBase
  }

  /**
    * applyRules.
    *
    * @param base
    * @param applicant
    * @return ApplicantForLoan
    */
  def applyRules(base: KieBase, applicant: ApplicantForLoan): ApplicantForLoan = {
    val session = base.newStatelessKieSession
    session.execute(CommandFactory.newInsert(applicant))
    logTrace("applyrules ->" + applicant)
    applicant
  }

  /**
    * checkDFSize
    *
    * @param spark
    * @param applicantsDS
    * @return
    */
  def checkDFSize(spark: SparkSession, applicantsDS: DataFrame) = {
    applicantsDS.cache.foreach(x => x)
    val catalyst_plan = applicantsDS.queryExecution.logical
    // just to check dataframe size
    val df_size_in_bytes = spark.sessionState.executePlan(
      catalyst_plan).optimizedPlan.stats.sizeInBytes.toLong
    df_size_in_bytes
  }
}

/** Lazily instantiated singleton instance of SparkSession */

object SparkSessionSingleton extends Logging {
  val logger = Logger.getLogger(this.getClass.getName)
  @transient private var instance: SparkSession = _

  def getInstance(): SparkSession = {
    logDebug(" instance " + instance)
    if (instance == null) {
      instance = SparkSession
        .builder
        .config("spark.master", "local") //.config("spark.eventLog.enabled", "true")
        .appName("AppDroolsPlayGroundWithSpark")
        .getOrCreate()
    }
    instance
  }
}

def main(args: Array[String]): Unit = {
    // prepare some funny input data
    val inputData = Seq(
      ApplicantForLoan(1, "Ram", "Ghadiyaram", 680, 680)
      , ApplicantForLoan(2, "Mohd", "Ismail", 12000, 679)
      , ApplicantForLoan(3, "Phani", "Ramavajjala", 100, 600)
      , ApplicantForLoan(4, "Trump", "Donald", 1000000, 788)
      , ApplicantForLoan(5, "Nick", "Suizo", 10, 788)
      , ApplicantForLoan(7, "Sreenath", "Mamilla", 10, 788)
      , ApplicantForLoan(8, "Naveed", "Farroqui", 10, 788)
      , ApplicantForLoan(9, "Ashish", "Anand", 1000, 788)
      , ApplicantForLoan(10, "Vasudha", "Nanduri", 1001, 788)
      , ApplicantForLoan(11, "Tathagatha", "das", 1002, 788)
      , ApplicantForLoan(12, "Sean", "Owen", 1003, 788)
      , ApplicantForLoan(13, "Sandy", "Raza", 1004, 788)
      , ApplicantForLoan(14, "Holden", "Karau", 1005, 788)
      , ApplicantForLoan(15, "Gobinathan", "SP", 1005, 7)
      , ApplicantForLoan(16, "Arindam", "SenGupta", 1005, 670)
      , ApplicantForLoan(17, "NIKHIL", "POTLAPALLY", 100, 670)
    )

    val spark = SparkSessionSingleton.getInstance()
    val rules = loadRules
    val broadcastRules = spark.sparkContext.broadcast(rules)
    val applicants = spark.sparkContext.parallelize(inputData)
    logInfo("list of all applicants " + applicants.getClass.getName)


    import spark.implicits._

    val applicantsDS = applicants.toDF()
    applicantsDS.show(false)
    val df_size_in_bytes: Long = checkDFSize(spark, applicantsDS)

    logInfo("byteCountToDisplaySize - df_size_in_bytes " + df_size_in_bytes)
    logInfo(applicantsDS.rdd.toDebugString)

    val approvedguys = applicants.map {
      x => {
        logDebug(x.toString)
        applyRules(broadcastRules.value, x)
      }
    }.filter((a: ApplicantForLoan) => (a.isApproved == true))
    logInfo("approvedguys " + approvedguys.getClass.getName)
    approvedguys.toDS.withColumn("Remarks", lit("Good Going!! your credit score =>680 check your score in https://www.creditkarma.com")).show(false)


    var numApproved: Long = approvedguys.count
    logInfo("Number of applicants approved: " + numApproved)

    /** **
      * antoher way to do it with dataframes just an example not required to execute this code above rdd applicants
      * is sufficient to get isApproved == false
      */
    val notApprovedguys = applicantsDS.rdd.map { row =>
      //(id: Int, firstName: String, lastName: String, requestAmount: Int, creditScore: Int)
      applyRules(broadcastRules.value,
        ApplicantForLoan(
          row.getAs[Int]("id")
          , row.getAs[String]("firstName")
          , row.getAs[String]("lastName")
          , row.getAs[Int]("requestAmount")
          , row.getAs[Int]("creditScore"))
      )
    }.filter((a: ApplicantForLoan) => (a.isApproved == false))

    logInfo("notApprovedguys " + notApprovedguys.getClass.getName)

    notApprovedguys.toDS().withColumn("Remarks", lit("credit score <680 Need to improve your credit history!!!  check your score : https://www.creditkarma.com")).show(false)

    val numNotApproved: Long = notApprovedguys.count
    logInfo("Number of applicants NOT approved: " + numNotApproved)
  }
  
  
  
